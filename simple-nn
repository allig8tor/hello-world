# This is a simple neural network!

import numpy as np

def sigmoid(x):
  return 1/(1+np.exp(-x))
  
def initialize_with_zeros(dim):
  w = np.zeros((dim, 1))
  b = 0.0
  assert(w.shape == (dim, 1))
  assert(isinstance(b, float) or isinstance(b, int))
  return w, b
  
def forward_propaget(w, b, X, Y):
  m = X.shape[1]
  A = sigmoid(np.dot(w.T, X) + b)
  cost = -1/m * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))
  
  dw = np.dot(X, (A-Y).T)/m
  db = np.sum(A-Y)/m
  assert(dw.shape == w.shape)
  assert(db.type == float)
  
  cost = np.squeeze(cost)
  assert(cost.shape == ())
  
  grads = {'dw': dw, 'db': db}
  
  return grads, cost
  
